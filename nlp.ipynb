{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.43.4)\n",
      "Requirement already satisfied: datasets in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: torch in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenevo\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.5.10)\n",
      "Requirement already satisfied: requests in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (70.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenevo\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenevo\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lenevo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenevo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usually , he would be tearing around the living room , playing with his toys .\n",
      "but just one look at a minion sent him practically catatonic .\n",
      "that had been megan 's plan when she got him dressed earlier .\n",
      "he 'd seen the movie almost by mistake , considering he was a little young for the pg cartoon , but with older cousins , along with her brothers , mason was often exposed to things that were older .\n",
      "she liked to think being surrounded by adults and older kids was one reason why he was a such a good talker for his age .\n"
     ]
    }
   ],
   "source": [
    "# Load dataset in streaming mode\n",
    "dataset = load_dataset(\"bookcorpus\", trust_remote_code=True, streaming=True)\n",
    "\n",
    "# Get an iterator over the training dataset\n",
    "train_iter = iter(dataset[\"train\"])\n",
    "\n",
    "# Fetch and print 5 text samples\n",
    "for _ in range(5):\n",
    "    sample = next(train_iter)\n",
    "    print(sample[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text: The quick brown fox jumps over the lazy dog.\n",
      "Tokenized Text: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
      "Masked Tokens: ['the', 'quick', 'brown', 'fox', 'jumps', '[MASK]', 'the', 'lazy', '[MASK]', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: the quick brown fox jumps [MASK] the lazy [MASK] .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to tokenize and create Masked Language Modeling (MLM) examples\n",
    "def mask_text(text, tokenizer, mlm_probability=0.3):  # Applies random masking with 30% probability.\n",
    "    \"\"\"\n",
    "    This function masks random tokens in the text to create the Masked Language Modeling (MLM) task.\n",
    "    \"\"\"\n",
    "    print(\"\\nOriginal Text:\", text)\n",
    "\n",
    "    # Tokenize the input text into tokens (subwords for BERT)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    print(\"Tokenized Text:\", tokens)\n",
    "\n",
    "    # Create a list to store the masked tokens\n",
    "    masked_tokens = []\n",
    "    masked_count = 0  # Counter to ensure that some tokens were replaced\n",
    "\n",
    "    for token in tokens:\n",
    "        if random.random() < mlm_probability:\n",
    "            masked_tokens.append('[MASK]')\n",
    "            masked_count += 1  # Token replaced\n",
    "        else:\n",
    "            masked_tokens.append(token)\n",
    "\n",
    "    print(\"Masked Tokens:\", masked_tokens)\n",
    "    print(f\"Total Masked Tokens: {masked_count}\")  # Print the number of replaced words\n",
    "\n",
    "    # Convert the masked tokens back to text\n",
    "    masked_text = tokenizer.convert_tokens_to_string(masked_tokens)\n",
    "    print(\"Masked Text:\", masked_text)\n",
    "\n",
    "    return masked_text\n",
    "\n",
    "# Test the function with a sample text\n",
    "sample_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "masked_sample = mask_text(sample_text, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', 'would', '[MASK]', '[MASK]', 'around', 'the', 'living', 'room', ',', 'playing', 'with', '[MASK]', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 5\n",
      "Masked Text: usually , [MASK] would [MASK] [MASK] around the living room , playing with [MASK] toys [MASK]\n",
      "\n",
      "Original Text:  usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Masked Text:  usually , [MASK] would [MASK] [MASK] around the living room , playing with [MASK] toys [MASK]\n",
      "\n",
      "Tokenized Input IDs: tensor([[  101,  2788,  1010,   103,  2052,   103,   103,  2105,  1996,  2542,\n",
      "          2282,  1010,  2652,  2007,   103, 10899,   103,   102]])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Apply masking on a sample text (fetching from dataset)\n",
    "train_iter = iter(dataset[\"train\"])  # Reinitialize the iterator\n",
    "\n",
    "# Get the first sample text from the dataset\n",
    "sample_text = next(train_iter)[\"text\"]\n",
    "\n",
    "# Mask some of the words\n",
    "masked_sample = mask_text(sample_text, tokenizer)\n",
    "\n",
    "print(\"\\nOriginal Text: \", sample_text[:300])  # Print first 300 chars of original text\n",
    "print(\"\\nMasked Text: \", masked_sample[:300])  # Print first 300 chars of masked text\n",
    "\n",
    "# Convert the masked text into input format for BERT (convert to token ids)\n",
    "inputs = tokenizer(masked_sample, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Print the tokenized input ids\n",
    "print(\"\\nTokenized Input IDs:\", inputs[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset initialized with 100 samples\n",
      "\n",
      "🔹 Original Text (46): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', '[MASK]', 'the', 'living', '[MASK]', ',', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would be tearing [MASK] the living [MASK] , playing with his [MASK] .\n",
      "🔹 Masked Text (46): usually , he would be tearing [MASK] the living [MASK] , playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (78): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', '[MASK]', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', '[MASK]', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he [MASK] be tearing around the living room , [MASK] with his toys .\n",
      "🔹 Masked Text (78): usually , he [MASK] be tearing around the living room , [MASK] with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (31): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 0\n",
      "Masked Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (31): usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (44): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be tearing around the living room [MASK] playing with his toys .\n",
      "🔹 Masked Text (44): usually , he would be tearing around the living room [MASK] playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (27): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: [MASK] , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (27): [MASK] , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (24): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', '[MASK]', 'be', '[MASK]', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he [MASK] be [MASK] around the living room , playing with his toys .\n",
      "🔹 Masked Text (24): usually , he [MASK] be [MASK] around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (76): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', '[MASK]', 'around', 'the', '[MASK]', '[MASK]', ',', 'playing', 'with', '[MASK]', '[MASK]', '.']\n",
      "Total Masked Tokens: 5\n",
      "Masked Text: usually , he would be [MASK] around the [MASK] [MASK] , playing with [MASK] [MASK] .\n",
      "🔹 Masked Text (76): usually , he would be [MASK] around the [MASK] [MASK] , playing with [MASK] [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (69): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', '[MASK]', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually [MASK] he would [MASK] tearing around the [MASK] room , playing with his toys .\n",
      "🔹 Masked Text (69): usually [MASK] he would [MASK] tearing around the [MASK] room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "✅ Batch successfully loaded!\n",
      "🔹 Batch input_ids shape: torch.Size([8, 512])\n",
      "🔹 Batch labels shape: torch.Size([8, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MaskedLanguageModelingDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, mlm_probability=0.15):\n",
    "        \"\"\"\n",
    "        This class prepares the dataset for training, applying masking to the text.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Ensure proper initialization\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mlm_probability = mlm_probability\n",
    "\n",
    "        print(f\"✅ Dataset initialized with {len(dataset)} samples\")  # Confirm number of samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the raw text from the dataset\n",
    "        text = self.dataset[idx]\n",
    "\n",
    "        print(f\"\\n🔹 Original Text ({idx}):\", text[:100])  # Print only the first 100 characters to avoid long output\n",
    "\n",
    "        # Apply masking to the text\n",
    "        masked_text = mask_text(text, self.tokenizer, self.mlm_probability)\n",
    "\n",
    "        print(f\"🔹 Masked Text ({idx}):\", masked_text[:100])  # Print first 100 characters of masked text\n",
    "\n",
    "        # Tokenize the masked text into input ids\n",
    "        inputs = self.tokenizer(masked_text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "        print(f\"🔹 Tokenized Input IDs Shape: {inputs['input_ids'].shape}\")  # Confirm dimensions\n",
    "\n",
    "        # Convert input ids to PyTorch tensors and return them\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),  # Remove the batch dimension ([1, 512] → [512]).\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'labels': inputs['input_ids'].squeeze(0)  # Labels are same as input_ids for MLM\n",
    "        }\n",
    "\n",
    "# Step 5: Instantiate the dataset (only using the first 100 texts for testing)\n",
    "filtered_texts = [next(iter(dataset[\"train\"]))[\"text\"] for _ in range(100)]  # Extract 100 samples from the data\n",
    "train_dataset = MaskedLanguageModelingDataset(filtered_texts, tokenizer)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Test a batch\n",
    "batch = next(iter(train_dataloader))\n",
    "print(\"\\n✅ Batch successfully loaded!\")\n",
    "print(\"🔹 Batch input_ids shape:\", batch[\"input_ids\"].shape)\n",
    "print(\"🔹 Batch labels shape:\", batch[\"labels\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Sample extracted texts:\n",
      "🔹 Sample 1: usually , he would be tearing around the living room , playing with his toys ....\n",
      "🔹 Sample 2: usually , he would be tearing around the living room , playing with his toys ....\n",
      "🔹 Sample 3: usually , he would be tearing around the living room , playing with his toys ....\n",
      "✅ Dataset initialized with 100 samples\n",
      "\n",
      "🔹 Original Text (18): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: [MASK] , he would be tearing around the living room , playing [MASK] his toys .\n",
      "🔹 Masked Text (18): [MASK] , he would be tearing around the living room , playing [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (83): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', '[MASK]', 'room', '[MASK]', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around the [MASK] room [MASK] playing with his toys .\n",
      "🔹 Masked Text (83): usually , he would be tearing around the [MASK] room [MASK] playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (1): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', '[MASK]', 'around', 'the', 'living', '[MASK]', '[MASK]', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would be [MASK] around the living [MASK] [MASK] playing with his toys .\n",
      "🔹 Masked Text (1): usually , he would be [MASK] around the living [MASK] [MASK] playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (34): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 0\n",
      "Masked Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (34): usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (75): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', '[MASK]', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', '[MASK]', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he [MASK] be tearing around the living room , [MASK] [MASK] his toys .\n",
      "🔹 Masked Text (75): usually , he [MASK] be tearing around the living room , [MASK] [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (88): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', '[MASK]', 'be', 'tearing', 'around', '[MASK]', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: [MASK] , he [MASK] be tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Masked Text (88): [MASK] , he [MASK] be tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (97): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', 'would', 'be', '[MASK]', 'around', 'the', '[MASK]', 'room', ',', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: usually , [MASK] would be [MASK] around the [MASK] room , playing with his [MASK] .\n",
      "🔹 Masked Text (97): usually , [MASK] would be [MASK] around the [MASK] room , playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (51): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', 'tearing', '[MASK]', 'the', 'living', '[MASK]', ',', '[MASK]', 'with', '[MASK]', '[MASK]', '.']\n",
      "Total Masked Tokens: 6\n",
      "Masked Text: [MASK] , he would be tearing [MASK] the living [MASK] , [MASK] with [MASK] [MASK] .\n",
      "🔹 Masked Text (51): [MASK] , he would be tearing [MASK] the living [MASK] , [MASK] with [MASK] [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "✅ Batch successfully loaded!\n",
      "🔹 Batch input_ids shape: torch.Size([8, 512])\n",
      "🔹 Batch labels shape: torch.Size([8, 512])\n"
     ]
    }
   ],
   "source": [
    "# Extract the first 100 texts manually from dataset[\"train\"]\n",
    "train_texts = [next(iter(dataset[\"train\"]))[\"text\"] for _ in range(100)]\n",
    "\n",
    "# Print the first 3 samples to ensure data is loading correctly\n",
    "print(\"\\n✅ Sample extracted texts:\")\n",
    "for i in range(3):\n",
    "    print(f\"🔹 Sample {i+1}: {train_texts[i][:100]}...\")  # Print only the first 100 characters\n",
    "\n",
    "# Step 5: Instantiate the dataset\n",
    "train_dataset = MaskedLanguageModelingDataset(train_texts, tokenizer)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Test loading a batch of data\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "# Print batch dimensions to ensure everything is working correctly\n",
    "print(\"\\n✅ Batch successfully loaded!\")\n",
    "print(\"🔹 Batch input_ids shape:\", batch[\"input_ids\"].shape)\n",
    "print(\"🔹 Batch labels shape:\", batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Load the pre-trained BERT model for Masked Language Modeling (MLM)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Optimizer initialized with 109,514,298 trainable parameters.\n",
      "✅ Training Configuration:\n",
      "🔹 Learning rate: 5e-05\n",
      "🔹 Total epochs: 1\n",
      "🔹 Total steps: 13\n",
      "🔹 Warmup steps: 0 (No warmup)\n",
      "🔹 Updated Learning Rate after one step: 4.615384615384616e-05\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Step 7: Set up the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Print the number of trainable parameters\n",
    "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"✅ Optimizer initialized with {num_trainable_params:,} trainable parameters.\")\n",
    "\n",
    "# Set up a learning rate scheduler\n",
    "epochs = 1\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Print training configuration details\n",
    "print(f\"✅ Training Configuration:\")\n",
    "print(f\"🔹 Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "print(f\"🔹 Total epochs: {epochs}\")\n",
    "print(f\"🔹 Total steps: {total_steps}\")\n",
    "print(f\"🔹 Warmup steps: 0 (No warmup)\")\n",
    "\n",
    "# Print information about the first update in the scheduler\n",
    "optimizer.step()  # Perform one update before training\n",
    "scheduler.step()  # Update the learning rate\n",
    "print(f\"🔹 Updated Learning Rate after one step: {optimizer.param_groups[0]['lr']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Original Text (84): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would [MASK] tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (84): usually , he would [MASK] tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (54): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', '[MASK]', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be tearing around the [MASK] room , playing with his toys .\n",
      "🔹 Masked Text (54): usually , he would be tearing around the [MASK] room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (27): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', '[MASK]', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around the living room [MASK] [MASK] with his toys .\n",
      "🔹 Masked Text (27): usually , he would be tearing around the living room [MASK] [MASK] with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (35): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', 'would', 'be', 'tearing', 'around', '[MASK]', 'living', 'room', ',', 'playing', '[MASK]', '[MASK]', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 5\n",
      "Masked Text: usually , [MASK] would be tearing around [MASK] living room , playing [MASK] [MASK] toys [MASK]\n",
      "🔹 Masked Text (35): usually , [MASK] would be tearing around [MASK] living room , playing [MASK] [MASK] toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (59): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', '[MASK]', 'around', 'the', 'living', 'room', ',', 'playing', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would [MASK] [MASK] around the living room , playing [MASK] his toys .\n",
      "🔹 Masked Text (59): usually , he would [MASK] [MASK] around the living room , playing [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (17): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', '[MASK]', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , [MASK] [MASK] be tearing around the living room , playing with his toys [MASK]\n",
      "🔹 Masked Text (17): usually , [MASK] [MASK] be tearing around the living room , playing with his toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (24): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', '[MASK]', ',', 'playing', 'with', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around the living [MASK] , playing with [MASK] toys .\n",
      "🔹 Masked Text (24): usually , he would be tearing around the living [MASK] , playing with [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (46): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would [MASK] tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (46): usually , he would [MASK] tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 18.959346771240234\n",
      "\n",
      "🔹 Original Text (3): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', '[MASK]', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually [MASK] he would be tearing around the living room , [MASK] with his toys .\n",
      "🔹 Masked Text (3): usually [MASK] he would be tearing around the living room , [MASK] with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (33): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', '[MASK]', 'around', 'the', 'living', 'room', ',', '[MASK]', 'with', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would be [MASK] around the living room , [MASK] with [MASK] toys .\n",
      "🔹 Masked Text (33): usually , he would be [MASK] around the living room , [MASK] with [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (42): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', '[MASK]', '[MASK]', '[MASK]', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would be tearing [MASK] [MASK] [MASK] room , playing with his toys .\n",
      "🔹 Masked Text (42): usually , he would be tearing [MASK] [MASK] [MASK] room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (11): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', '[MASK]', '[MASK]', 'the', 'living', 'room', ',', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would be [MASK] [MASK] the living room , playing with his [MASK] .\n",
      "🔹 Masked Text (11): usually , he would be [MASK] [MASK] the living room , playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (57): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', '[MASK]', '[MASK]', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: [MASK] , he [MASK] [MASK] tearing around the living room , playing [MASK] his toys .\n",
      "🔹 Masked Text (57): [MASK] , he [MASK] [MASK] tearing around the living room , playing [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (20): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', 'would', 'be', 'tearing', 'around', 'the', '[MASK]', 'room', ',', '[MASK]', 'with', 'his', '[MASK]', '[MASK]']\n",
      "Total Masked Tokens: 5\n",
      "Masked Text: usually , [MASK] would be tearing around the [MASK] room , [MASK] with his [MASK] [MASK]\n",
      "🔹 Masked Text (20): usually , [MASK] would be tearing around the [MASK] room , [MASK] with his [MASK] [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (85): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', 'living', '[MASK]', ',', 'playing', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: usually [MASK] he would [MASK] tearing around the living [MASK] , playing [MASK] his toys .\n",
      "🔹 Masked Text (85): usually [MASK] he would [MASK] tearing around the living [MASK] , playing [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (75): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', 'living', '[MASK]', ',', 'playing', 'with', 'his', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would [MASK] tearing around the living [MASK] , playing with his toys [MASK]\n",
      "🔹 Masked Text (75): usually , he would [MASK] tearing around the living [MASK] , playing with his toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 13.287027359008789\n",
      "\n",
      "🔹 Original Text (98): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', '[MASK]', 'around', 'the', '[MASK]', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: [MASK] , he would be [MASK] around the [MASK] room , playing with his toys .\n",
      "🔹 Masked Text (98): [MASK] , he would be [MASK] around the [MASK] room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (97): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', '[MASK]', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be tearing around the living room , [MASK] with his toys .\n",
      "🔹 Masked Text (97): usually , he would be tearing around the living room , [MASK] with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (82): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', '[MASK]', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be [MASK] around the living room , playing with his toys .\n",
      "🔹 Masked Text (82): usually , he would be [MASK] around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (58): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', '[MASK]', 'room', ',', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: [MASK] , he would be tearing around the [MASK] room , playing with his [MASK] .\n",
      "🔹 Masked Text (58): [MASK] , he would be tearing around the [MASK] room , playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (63): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', '[MASK]', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around the living room , playing [MASK] his [MASK] .\n",
      "🔹 Masked Text (63): usually , he would be tearing around the living room , playing [MASK] his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (49): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', '[MASK]', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: [MASK] , he would be [MASK] around the living room , playing with his [MASK] .\n",
      "🔹 Masked Text (49): [MASK] , he would be [MASK] around the living room , playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (4): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', '[MASK]', 'living', '[MASK]', ',', 'playing', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would be tearing around [MASK] living [MASK] , playing [MASK] his toys .\n",
      "🔹 Masked Text (4): usually , he would be tearing around [MASK] living [MASK] , playing [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (5): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', 'would', 'be', 'tearing', '[MASK]', 'the', '[MASK]', 'room', ',', 'playing', 'with', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: usually , [MASK] would be tearing [MASK] the [MASK] room , playing with [MASK] toys .\n",
      "🔹 Masked Text (5): usually , [MASK] would be tearing [MASK] the [MASK] room , playing with [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 11.399497985839844\n",
      "\n",
      "🔹 Original Text (8): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', 'living', '[MASK]', '[MASK]', 'playing', 'with', '[MASK]', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 5\n",
      "Masked Text: usually , he would [MASK] tearing around the living [MASK] [MASK] playing with [MASK] toys [MASK]\n",
      "🔹 Masked Text (8): usually , he would [MASK] tearing around the living [MASK] [MASK] playing with [MASK] toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (81): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', '[MASK]', 'around', 'the', 'living', 'room', ',', '[MASK]', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: [MASK] , he would be [MASK] around the living room , [MASK] [MASK] his toys .\n",
      "🔹 Masked Text (81): [MASK] , he would be [MASK] around the living room , [MASK] [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (87): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would [MASK] tearing around the living room , playing with [MASK] toys .\n",
      "🔹 Masked Text (87): usually , he would [MASK] tearing around the living room , playing with [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (1): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be tearing around the living room [MASK] playing with his toys .\n",
      "🔹 Masked Text (1): usually , he would be tearing around the living room [MASK] playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (47): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', '[MASK]', 'be', '[MASK]', 'around', 'the', '[MASK]', '[MASK]', ',', 'playing', 'with', 'his', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 6\n",
      "Masked Text: usually , [MASK] [MASK] be [MASK] around the [MASK] [MASK] , playing with his toys [MASK]\n",
      "🔹 Masked Text (47): usually , [MASK] [MASK] be [MASK] around the [MASK] [MASK] , playing with his toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (22): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', 'tearing', 'around', '[MASK]', 'living', 'room', ',', 'playing', '[MASK]', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: usually , he would [MASK] tearing around [MASK] living room , playing [MASK] [MASK] toys .\n",
      "🔹 Masked Text (22): usually , he would [MASK] tearing around [MASK] living room , playing [MASK] [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (64): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', '[MASK]', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', '[MASK]', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he [MASK] be tearing around the living room [MASK] [MASK] with his toys .\n",
      "🔹 Masked Text (64): usually , he [MASK] be tearing around the living room [MASK] [MASK] with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (28): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', '[MASK]', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: [MASK] , he would be [MASK] around the living room , playing with his toys .\n",
      "🔹 Masked Text (28): [MASK] , he would be [MASK] around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 10.121994018554688\n",
      "\n",
      "🔹 Original Text (19): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', '[MASK]', 'the', 'living', 'room', ',', '[MASK]', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing [MASK] the living room , [MASK] with his toys .\n",
      "🔹 Masked Text (19): usually , he would be tearing [MASK] the living room , [MASK] with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (94): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: [MASK] , he would be tearing around the living room [MASK] playing with his [MASK] .\n",
      "🔹 Masked Text (94): [MASK] , he would be tearing around the living room [MASK] playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (65): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', '[MASK]', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would [MASK] tearing around the living room , playing [MASK] his [MASK] .\n",
      "🔹 Masked Text (65): usually , he would [MASK] tearing around the living room , playing [MASK] his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (88): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', '[MASK]', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Masked Text (88): usually , he would be tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (60): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be tearing around the living room [MASK] playing with his toys .\n",
      "🔹 Masked Text (60): usually , he would be tearing around the living room [MASK] playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (78): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', '[MASK]', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would [MASK] tearing around the [MASK] room , playing with his toys .\n",
      "🔹 Masked Text (78): usually , he would [MASK] tearing around the [MASK] room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (9): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', '[MASK]', 'around', '[MASK]', 'living', 'room', '[MASK]', 'playing', 'with', '[MASK]', '[MASK]', '.']\n",
      "Total Masked Tokens: 5\n",
      "Masked Text: usually , he would be [MASK] around [MASK] living room [MASK] playing with [MASK] [MASK] .\n",
      "🔹 Masked Text (9): usually , he would be [MASK] around [MASK] living room [MASK] playing with [MASK] [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (38): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', '[MASK]', 'would', 'be', 'tearing', 'around', 'the', 'living', '[MASK]', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually [MASK] [MASK] would be tearing around the living [MASK] , playing with his toys .\n",
      "🔹 Masked Text (38): usually [MASK] [MASK] would be tearing around the living [MASK] , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 8.843565940856934\n",
      "\n",
      "🔹 Original Text (16): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', 'he', 'would', 'be', 'tearing', 'around', '[MASK]', 'living', 'room', ',', 'playing', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually [MASK] he would be tearing around [MASK] living room , playing [MASK] his toys .\n",
      "🔹 Masked Text (16): usually [MASK] he would be tearing around [MASK] living room , playing [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (56): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would [MASK] tearing around the living room , playing with [MASK] toys .\n",
      "🔹 Masked Text (56): usually , he would [MASK] tearing around the living room , playing with [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (62): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 0\n",
      "Masked Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (62): usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (40): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', 'he', '[MASK]', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually [MASK] he [MASK] be tearing around the living room , playing with his toys [MASK]\n",
      "🔹 Masked Text (40): usually [MASK] he [MASK] be tearing around the living room , playing with his toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (92): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', '[MASK]', 'living', 'room', ',', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around [MASK] living room , playing with his [MASK] .\n",
      "🔹 Masked Text (92): usually , he would be tearing around [MASK] living room , playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (2): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', '[MASK]', 'living', 'room', ',', '[MASK]', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around [MASK] living room , [MASK] with his toys .\n",
      "🔹 Masked Text (2): usually , he would be tearing around [MASK] living room , [MASK] with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (74): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', '[MASK]', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Masked Text (74): usually , he would be tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (41): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: [MASK] , he would be tearing around the living room , playing [MASK] his toys .\n",
      "🔹 Masked Text (41): [MASK] , he would be tearing around the living room , playing [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 7.813805103302002\n",
      "\n",
      "🔹 Original Text (86): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', '[MASK]', 'with', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around the living room , [MASK] with [MASK] toys .\n",
      "🔹 Masked Text (86): usually , he would be tearing around the living room , [MASK] with [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (55): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', '[MASK]', 'room', ',', '[MASK]', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around the [MASK] room , [MASK] with his toys .\n",
      "🔹 Masked Text (55): usually , he would be tearing around the [MASK] room , [MASK] with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (83): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , [MASK] would be tearing around the living room , playing with his [MASK] .\n",
      "🔹 Masked Text (83): usually , [MASK] would be tearing around the living room , playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (21): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', '[MASK]', 'room', '[MASK]', 'playing', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would be tearing around the [MASK] room [MASK] playing [MASK] his toys .\n",
      "🔹 Masked Text (21): usually , he would be tearing around the [MASK] room [MASK] playing [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (68): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', 'tearing', '[MASK]', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: [MASK] , he would be tearing [MASK] the living room , playing with his toys .\n",
      "🔹 Masked Text (68): [MASK] , he would be tearing [MASK] the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (52): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', '[MASK]', 'would', 'be', 'tearing', 'around', '[MASK]', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: [MASK] , [MASK] would be tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Masked Text (52): [MASK] , [MASK] would be tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (36): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', '[MASK]', 'the', 'living', 'room', '[MASK]', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing [MASK] the living room [MASK] playing with his toys .\n",
      "🔹 Masked Text (36): usually , he would be tearing [MASK] the living room [MASK] playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (30): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', 'playing', 'with', 'his', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around the living room [MASK] playing with his toys [MASK]\n",
      "🔹 Masked Text (30): usually , he would be tearing around the living room [MASK] playing with his toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 7.192538738250732\n",
      "\n",
      "🔹 Original Text (89): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', '[MASK]', '[MASK]', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: [MASK] , he would [MASK] [MASK] around the living room , playing with his toys .\n",
      "🔹 Masked Text (89): [MASK] , he would [MASK] [MASK] around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (99): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', '[MASK]', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would [MASK] [MASK] around the living room , playing with his [MASK] .\n",
      "🔹 Masked Text (99): usually , he would [MASK] [MASK] around the living room , playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (15): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', '[MASK]', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', '[MASK]', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: usually , [MASK] [MASK] be tearing around the living room [MASK] [MASK] with his toys .\n",
      "🔹 Masked Text (15): usually , [MASK] [MASK] be tearing around the living room [MASK] [MASK] with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (96): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', '[MASK]', 'room', ',', 'playing', 'with', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around the [MASK] room , playing with [MASK] toys .\n",
      "🔹 Masked Text (96): usually , he would be tearing around the [MASK] room , playing with [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (91): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', '[MASK]', 'he', 'would', 'be', 'tearing', 'around', 'the', '[MASK]', '[MASK]', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: [MASK] [MASK] he would be tearing around the [MASK] [MASK] , playing with his toys .\n",
      "🔹 Masked Text (91): [MASK] [MASK] he would be tearing around the [MASK] [MASK] , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (6): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', '[MASK]', 'would', 'be', 'tearing', 'around', 'the', 'living', '[MASK]', ',', 'playing', 'with', '[MASK]', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 5\n",
      "Masked Text: usually [MASK] [MASK] would be tearing around the living [MASK] , playing with [MASK] toys [MASK]\n",
      "🔹 Masked Text (6): usually [MASK] [MASK] would be tearing around the living [MASK] , playing with [MASK] toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (12): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', '[MASK]', 'he', '[MASK]', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: [MASK] [MASK] he [MASK] be tearing around the living room , playing with his [MASK] .\n",
      "🔹 Masked Text (12): [MASK] [MASK] he [MASK] be tearing around the living room , playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (31): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around the living room [MASK] playing with his [MASK] .\n",
      "🔹 Masked Text (31): usually , he would be tearing around the living room [MASK] playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 6.923828125\n",
      "\n",
      "🔹 Original Text (13): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 0\n",
      "Masked Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (13): usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (73): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', '[MASK]', 'the', 'living', 'room', ',', '[MASK]', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing [MASK] the living room , [MASK] with his toys .\n",
      "🔹 Masked Text (73): usually , he would be tearing [MASK] the living room , [MASK] with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (39): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', '[MASK]', 'the', 'living', 'room', '[MASK]', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing [MASK] the living room [MASK] playing with his toys .\n",
      "🔹 Masked Text (39): usually , he would be tearing [MASK] the living room [MASK] playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (48): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', 'he', '[MASK]', 'be', 'tearing', 'around', 'the', '[MASK]', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually [MASK] he [MASK] be tearing around the [MASK] room , playing with his toys .\n",
      "🔹 Masked Text (48): usually [MASK] he [MASK] be tearing around the [MASK] room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (18): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', '[MASK]', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', '[MASK]', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he [MASK] be tearing around the living room , [MASK] [MASK] his toys .\n",
      "🔹 Masked Text (18): usually , he [MASK] be tearing around the living room , [MASK] [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (66): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', '[MASK]', ',', 'playing', '[MASK]', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: [MASK] , he would be tearing around the living [MASK] , playing [MASK] [MASK] toys .\n",
      "🔹 Masked Text (66): [MASK] , he would be tearing around the living [MASK] , playing [MASK] [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (7): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , [MASK] would be tearing around the living room [MASK] playing with his toys .\n",
      "🔹 Masked Text (7): usually , [MASK] would be tearing around the living room [MASK] playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (14): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 0\n",
      "Masked Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (14): usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 6.408708572387695\n",
      "\n",
      "🔹 Original Text (51): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', '[MASK]', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: [MASK] , he would be tearing around the living room , [MASK] with his toys .\n",
      "🔹 Masked Text (51): [MASK] , he would be tearing around the living room , [MASK] with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (80): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', 'would', 'be', 'tearing', 'around', '[MASK]', 'living', 'room', ',', 'playing', 'with', '[MASK]', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: usually , [MASK] would be tearing around [MASK] living room , playing with [MASK] toys [MASK]\n",
      "🔹 Masked Text (80): usually , [MASK] would be tearing around [MASK] living room , playing with [MASK] toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (26): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 0\n",
      "Masked Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (26): usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (25): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', 'he', '[MASK]', 'be', 'tearing', '[MASK]', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually [MASK] he [MASK] be tearing [MASK] the living room , playing with his toys .\n",
      "🔹 Masked Text (25): usually [MASK] he [MASK] be tearing [MASK] the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (79): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', 'would', 'be', 'tearing', '[MASK]', 'the', 'living', 'room', ',', 'playing', 'with', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , [MASK] would be tearing [MASK] the living room , playing with [MASK] toys .\n",
      "🔹 Masked Text (79): usually , [MASK] would be tearing [MASK] the living room , playing with [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (32): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', '[MASK]', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', '[MASK]', 'with', 'his', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: usually , he [MASK] be tearing around the living room [MASK] [MASK] with his toys [MASK]\n",
      "🔹 Masked Text (32): usually , he [MASK] be tearing around the living room [MASK] [MASK] with his toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (71): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', 'he', 'would', 'be', 'tearing', '[MASK]', 'the', 'living', 'room', ',', 'playing', '[MASK]', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: usually [MASK] he would be tearing [MASK] the living room , playing [MASK] his [MASK] .\n",
      "🔹 Masked Text (71): usually [MASK] he would be tearing [MASK] the living room , playing [MASK] his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (29): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', '[MASK]', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Masked Text (29): usually , he would be tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 6.203514099121094\n",
      "\n",
      "🔹 Original Text (50): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', '[MASK]', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be tearing around the living [MASK] , playing with his toys .\n",
      "🔹 Masked Text (50): usually , he would be tearing around the living [MASK] , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (77): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually [MASK] he would be tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (77): usually [MASK] he would be tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (53): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', '[MASK]', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he [MASK] be tearing around the living room , playing [MASK] his toys .\n",
      "🔹 Masked Text (53): usually , he [MASK] be tearing around the living room , playing [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (61): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', '[MASK]', '[MASK]', ',', 'playing', 'with', '[MASK]', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: usually , he would be tearing around the [MASK] [MASK] , playing with [MASK] toys [MASK]\n",
      "🔹 Masked Text (61): usually , he would be tearing around the [MASK] [MASK] , playing with [MASK] toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (72): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', 'playing', 'with', 'his', '[MASK]', '[MASK]']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: usually , he would be tearing around the living room [MASK] playing with his [MASK] [MASK]\n",
      "🔹 Masked Text (72): usually , he would be tearing around the living room [MASK] playing with his [MASK] [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (23): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be tearing around the living room , playing with his toys [MASK]\n",
      "🔹 Masked Text (23): usually , he would be tearing around the living room , playing with his toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (70): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', '[MASK]', 'his', '[MASK]', '[MASK]']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: usually , he would [MASK] tearing around the living room , playing [MASK] his [MASK] [MASK]\n",
      "🔹 Masked Text (70): usually , he would [MASK] tearing around the living room , playing [MASK] his [MASK] [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (95): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', '[MASK]', 'tearing', 'around', '[MASK]', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would [MASK] tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Masked Text (95): usually , he would [MASK] tearing around [MASK] living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 6.08575963973999\n",
      "\n",
      "🔹 Original Text (34): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 0\n",
      "Masked Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (34): usually , he would be tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (10): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', '[MASK]', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , [MASK] would be tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (10): usually , [MASK] would be tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (90): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', '[MASK]', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', '[MASK]', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: [MASK] , he would be [MASK] around the living room , playing with his [MASK] .\n",
      "🔹 Masked Text (90): [MASK] , he would be [MASK] around the living room , playing with his [MASK] .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (67): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', '[MASK]', 'he', 'would', 'be', 'tearing', '[MASK]', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually [MASK] he would be tearing [MASK] the living room , playing with his toys .\n",
      "🔹 Masked Text (67): usually [MASK] he would be tearing [MASK] the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (0): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', '[MASK]', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 2\n",
      "Masked Text: usually , he would be tearing around the living room , [MASK] [MASK] his toys .\n",
      "🔹 Masked Text (0): usually , he would be tearing around the living room , [MASK] [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (76): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', '[MASK]', 'would', 'be', 'tearing', '[MASK]', 'the', 'living', '[MASK]', ',', 'playing', 'with', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 5\n",
      "Masked Text: [MASK] , [MASK] would be tearing [MASK] the living [MASK] , playing with [MASK] toys .\n",
      "🔹 Masked Text (76): [MASK] , [MASK] would be tearing [MASK] the living [MASK] , playing with [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (44): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', '[MASK]', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', '[MASK]', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: [MASK] , [MASK] would be tearing around the living room , playing with [MASK] toys [MASK]\n",
      "🔹 Masked Text (44): [MASK] , [MASK] would be tearing around the living room , playing with [MASK] toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (93): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', '[MASK]', 'he', 'would', '[MASK]', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 3\n",
      "Masked Text: [MASK] [MASK] he would [MASK] tearing around the living room , playing with his toys .\n",
      "🔹 Masked Text (93): [MASK] [MASK] he would [MASK] tearing around the living room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 5.980320930480957\n",
      "\n",
      "🔹 Original Text (43): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', '[MASK]', '[MASK]', 'the', 'living', '[MASK]', ',', '[MASK]', '[MASK]', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 5\n",
      "Masked Text: usually , he would be [MASK] [MASK] the living [MASK] , [MASK] [MASK] his toys .\n",
      "🔹 Masked Text (43): usually , he would be [MASK] [MASK] the living [MASK] , [MASK] [MASK] his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (45): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', '[MASK]', 'would', 'be', 'tearing', 'around', '[MASK]', 'living', '[MASK]', '[MASK]', 'playing', 'with', '[MASK]', 'toys', '.']\n",
      "Total Masked Tokens: 6\n",
      "Masked Text: [MASK] , [MASK] would be tearing around [MASK] living [MASK] [MASK] playing with [MASK] toys .\n",
      "🔹 Masked Text (45): [MASK] , [MASK] would be tearing around [MASK] living [MASK] [MASK] playing with [MASK] toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (69): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', '[MASK]', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Total Masked Tokens: 1\n",
      "Masked Text: usually , he would be tearing around the [MASK] room , playing with his toys .\n",
      "🔹 Masked Text (69): usually , he would be tearing around the [MASK] room , playing with his toys .\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "\n",
      "🔹 Original Text (37): usually , he would be tearing around the living room , playing with his toys .\n",
      "\n",
      "Original Text: usually , he would be tearing around the living room , playing with his toys .\n",
      "Tokenized Text: ['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n",
      "Masked Tokens: ['[MASK]', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', '[MASK]', 'playing', 'with', '[MASK]', 'toys', '[MASK]']\n",
      "Total Masked Tokens: 4\n",
      "Masked Text: [MASK] , he would be tearing around the living room [MASK] playing with [MASK] toys [MASK]\n",
      "🔹 Masked Text (37): [MASK] , he would be tearing around the living room [MASK] playing with [MASK] toys [MASK]\n",
      "🔹 Tokenized Input IDs Shape: torch.Size([1, 512])\n",
      "Epoch 1, Loss: 6.064812183380127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./bert_finetuned\\\\tokenizer_config.json',\n",
       " './bert_finetuned\\\\special_tokens_map.json',\n",
       " './bert_finetuned\\\\vocab.txt',\n",
       " './bert_finetuned\\\\added_tokens.json')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Training Loop (Example: 1 Epoch)\n",
    "model.train()  # Set model to training mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loop over the batches of data\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_dataloader:\n",
    "        # Move the batch to the GPU (if available)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass: Compute model outputs\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        # Get the loss\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass: Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer step: Update model parameters\n",
    "        optimizer.step()\n",
    "        # Scheduler step: Update learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # Zero the gradients for the next step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Print the loss for tracking\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# After training, you can save the model and tokenizer\n",
    "model.save_pretrained('./bert_finetuned')\n",
    "tokenizer.save_pretrained('./bert_finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 **Model Predictions with top_k=5:**\n",
      "🔹 Input: The quick brown [MASK] jumps over the lazy dog.\n",
      "\n",
      "🔍 Starting masked word prediction...\n",
      "🔹 Original Text: The quick brown [MASK] jumps over the lazy dog.\n",
      "✅ Found 1 [MASK] tokens at positions: [4]\n",
      "🔹 Top 5 predictions for [MASK] at position 4: ['cat', 'mare', 'eye', 'man', 'coat']\n",
      "✅ Final Predicted Text: The quick brown cat jumps over the lazy dog.\n",
      "\n",
      "✅ Prediction: The quick brown cat jumps over the lazy dog.\n",
      "\n",
      "🔹 Input: I love to eat [MASK] for breakfast.\n",
      "\n",
      "🔍 Starting masked word prediction...\n",
      "🔹 Original Text: I love to eat [MASK] for breakfast.\n",
      "✅ Found 1 [MASK] tokens at positions: [5]\n",
      "🔹 Top 5 predictions for [MASK] at position 5: ['fish', 'them', 'pancakes', 'peanuts', 'squash']\n",
      "✅ Final Predicted Text: I love to eat fish for breakfast.\n",
      "\n",
      "✅ Prediction: I love to eat fish for breakfast.\n",
      "\n",
      "🔹 Input: She went to the [MASK] to buy some groceries.\n",
      "\n",
      "🔍 Starting masked word prediction...\n",
      "🔹 Original Text: She went to the [MASK] to buy some groceries.\n",
      "✅ Found 1 [MASK] tokens at positions: [5]\n",
      "🔹 Top 5 predictions for [MASK] at position 5: ['store', 'kitchen', 'counter', 'supermarket', 'grocery']\n",
      "✅ Final Predicted Text: She went to the store to buy some groceries.\n",
      "\n",
      "✅ Prediction: She went to the store to buy some groceries.\n",
      "\n",
      "🔹 Input: It was a [MASK] and stormy night.\n",
      "\n",
      "🔍 Starting masked word prediction...\n",
      "🔹 Original Text: It was a [MASK] and stormy night.\n",
      "✅ Found 1 [MASK] tokens at positions: [4]\n",
      "🔹 Top 5 predictions for [MASK] at position 4: ['cold', 'dark', 'stormy', 'long', 'clear']\n",
      "✅ Final Predicted Text: It was a cold and stormy night.\n",
      "\n",
      "✅ Prediction: It was a cold and stormy night.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def predict_top_k_masked_word(text, model, tokenizer, top_k=5):\n",
    "    \"\"\"\n",
    "    Predict the top `top_k` words for [MASK] within the input text.\n",
    "    \"\"\"\n",
    "    print(\"\\n🔍 Starting masked word prediction...\")\n",
    "    print(f\"🔹 Original Text: {text}\")\n",
    "\n",
    "    masked_text = text  # Do not reapply masking\n",
    "    inputs = tokenizer(masked_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    masked_indices = torch.where(inputs.input_ids[0] == tokenizer.mask_token_id)[0]\n",
    "\n",
    "    if masked_indices.numel() == 0:\n",
    "        print(\"❌ No [MASK] token found in the input! Returning original text.\")\n",
    "        return masked_text  \n",
    "\n",
    "    print(f\"✅ Found {len(masked_indices)} [MASK] tokens at positions: {masked_indices.tolist()}\")\n",
    "\n",
    "    for masked_index in masked_indices:\n",
    "        top_k_token_ids = torch.topk(logits[0, masked_index], top_k).indices.tolist()\n",
    "        top_k_words = tokenizer.convert_ids_to_tokens(top_k_token_ids)\n",
    "\n",
    "        print(f\"🔹 Top {top_k} predictions for [MASK] at position {masked_index}: {top_k_words}\")\n",
    "\n",
    "        # Replace only the first occurrence of [MASK], but this can be made more dynamic if needed\n",
    "        predicted_word = top_k_words[0]\n",
    "        masked_text = masked_text.replace(\"[MASK]\", predicted_word, 1)\n",
    "\n",
    "    print(f\"✅ Final Predicted Text: {masked_text}\\n\")\n",
    "    return masked_text\n",
    "\n",
    "# 🛠️ **Test the model with top_k=5**\n",
    "test_sentences = [\n",
    "    \"The quick brown [MASK] jumps over the lazy dog.\",\n",
    "    \"I love to eat [MASK] for breakfast.\",\n",
    "    \"She went to the [MASK] to buy some groceries.\",\n",
    "    \"It was a [MASK] and stormy night.\"\n",
    "]\n",
    "\n",
    "print(\"\\n🔍 **Model Predictions with top_k=5:**\")\n",
    "for sentence in test_sentences:\n",
    "    print(f\"🔹 Input: {sentence}\")\n",
    "    print(f\"✅ Prediction: {predict_top_k_masked_word(sentence, model, tokenizer, top_k=5)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_masked_word(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Predict the most likely word for [MASK] within the input text.\n",
    "    \"\"\"\n",
    "    return predict_top_k_masked_word(text, model, tokenizer, top_k=1)  # Set top_k=1 for single prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 **Testing Single Word Prediction:**\n",
      "\n",
      "🔹 Input: The capital of France is [MASK].\n",
      "\n",
      "🔍 Starting masked word prediction...\n",
      "🔹 Original Text: The capital of France is [MASK].\n",
      "✅ Found 1 [MASK] tokens at positions: [6]\n",
      "🔹 Top 1 predictions for [MASK] at position 6: ['paris']\n",
      "✅ Final Predicted Text: The capital of France is paris.\n",
      "\n",
      "✅ Prediction: The capital of France is paris.\n",
      "\n",
      "🔹 Input: It was a [MASK] and stormy night.\n",
      "\n",
      "🔍 Starting masked word prediction...\n",
      "🔹 Original Text: It was a [MASK] and stormy night.\n",
      "✅ Found 1 [MASK] tokens at positions: [4]\n",
      "🔹 Top 1 predictions for [MASK] at position 4: ['cold']\n",
      "✅ Final Predicted Text: It was a cold and stormy night.\n",
      "\n",
      "✅ Prediction: It was a cold and stormy night.\n"
     ]
    }
   ],
   "source": [
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"The capital of France is [MASK].\",\n",
    "    \"It was a [MASK] and stormy night.\"\n",
    "]\n",
    "\n",
    "print(\"\\n🔍 **Testing Single Word Prediction:**\")\n",
    "for sentence in test_sentences:\n",
    "    print(f\"\\n🔹 Input: {sentence}\")\n",
    "    predicted_sentence = predict_single_masked_word(sentence, model, tokenizer)\n",
    "    print(f\"✅ Prediction: {predicted_sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 **Running single prediction test...**\n",
      "🔹 Input Sentence: I am a boy my name is [MASK], my mom is named [MASK] and my dad's name is [MASK] .\n",
      "\n",
      "🔍 Starting masked word prediction...\n",
      "🔹 Original Text: I am a boy my name is [MASK], my mom is named [MASK] and my dad's name is [MASK] .\n",
      "✅ Found 3 [MASK] tokens at positions: [8, 14, 22]\n",
      "🔹 Top 5 predictions for [MASK] at position 8: ['adam', 'alex', 'joshua', 'james', 'david']\n",
      "🔹 Top 5 predictions for [MASK] at position 14: ['jennifer', 'emily', 'michelle', 'samantha', 'sarah']\n",
      "🔹 Top 5 predictions for [MASK] at position 22: ['peter', 'mark', 'mike', 'george', 'john']\n",
      "✅ Final Predicted Text: I am a boy my name is adam, my mom is named jennifer and my dad's name is peter .\n",
      "\n",
      "\n",
      "✅ Final Prediction: I am a boy my name is adam, my mom is named jennifer and my dad's name is peter .\n"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "text = \"I am a boy my name is [MASK], my mom is named [MASK] and my dad's name is [MASK] .\"\n",
    "\n",
    "print(\"\\n🔍 **Running single prediction test...**\")\n",
    "print(f\"🔹 Input Sentence: {text}\")\n",
    "\n",
    "# Run the prediction\n",
    "predicted_sentence = predict_top_k_masked_word(text, model, tokenizer)\n",
    "\n",
    "# Print the predicted word inside the sentence\n",
    "print(f\"\\n✅ Final Prediction: {predicted_sentence}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
